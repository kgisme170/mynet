启动集群:
1. 启动Master
$SPARK_HOME/sbin/start-master.sh

2. 启动工作节点
$SPARK_HOME/sbin/spark-class org.apache.spark.deploy.worker.Worker<Spark-Master> &

这个Spark-Master就是Spark URL，在用户界面顶端出现的Spark Master at:

3. 使用jdbc
spark-submit --driver-class-path /home/a/.m2/repository/mysql/mysql-connector-java/5.1.39/mysql-connector-java-5.1.39.jar --jars target/myspark-1-1.0-SNAPSHOT.jar --class jdbcMysql target/myspark-1-1.0-SNAPSHOT.jar

4. useKafka
5. dubbo

---------------
question

Why java has "List.toArray()" but not "Array.toList()"?

Array doesn't have a "toList" function, while we need "Arrays.asList" helper functions to do the conversion?

This is quite odd: in OOP, List has its own function to convert to Array, but Array needs some helper functions to convert to List: why not let Arrays has a "toList" function, and what's the reason behind this java design?

Thanks a lot.

----------------
java stream.peek() doesn't return any elements?

I just tried this:

    Stream sf1 = Stream.of("a1", "b1").flatMap(str->Arrays.stream(str.split("")));
    //System.out.println(sf1.count()); --->will print "4"
    sf1.peek(str -> System.out.println(str));

Nothing is being output, why?

-----------------
Java Collectors.groupingBy(): how to use "identify()" as first parameter

    String init[] = { "One", "Two", "Three", "One", "Two", "Three" };
    List list1 = new ArrayList(Arrays.asList(init));
    Stream<String> ss3 = list1.stream();
    Map<String, long> msl = ss3.collect(
        Collectors.groupingBy(Function.identity(), counting()));//compilation failure

Seems that the 1st parameter of groupingBy needs to be a function reference, so I changed it to:

    Map<String, long> msl = ss3.collect(Collectors.groupingBy(Function::identity, counting()));

It doesn't compile either. How to fix it?

-----------------

Java: Collectors.groupingBy doesn't compile with stream

I've got this program:

    class City {
        private String name;

        public String getName() {
            return name;
        }
        private String state;

        public String getState() {
            return state;
        }

        private int population;

        public int getPopulation() {
            return population;
        }

        public City(String n, String s, int p) {
            name = n;
            state = s;
            population = p;
        }
    }
    public static void main(String[] args) {
        City [] cities = {
                new City("Beijing", "Bj", 2000),
                new City("Shenzhen", "Guangdong", 2000),
                new City("Zhuhai", "Guangdong", 1500)};
        List lc = new ArrayList(Arrays.asList(cities));
        Stream<String> slc = lc.stream();
        Map<String, Long> map = slc.collect(
                Collectors.groupingBy(City::getState, Collectors.counting()));
    }

The last line doesn't compile, saying cannot deduce generic type. Well the usage is copied from <<Java core programming>> with minor changes, so where did I get wrong and how to fix it?
Thanks a lot.
-------------------

Java: int stream throws ClassCastException when calling "reduce()" function.

Just 2 lines of code:

    List<Integer> values = new ArrayList(Arrays.asList(new int[]{3, 4, 5, 6}));
    values.stream().filter(x -> x > 3).reduce((x, y) -> x + y);

The last line throws out:

    Exception in thread "main" java.lang.ClassCastException: [I cannot be cast to java.lang.Integer

If I remove the "filter()" function then it's OK, but "filter()" returns a new stream, right?

I tried another:

    values.stream().reduce(0, (x, y) -> x + y);

This time, not "filter()" call, but still throws out the same exception.

Where this exception came from, and how to fix it?

Thanks a lot.

---------------------
If we use Fork/join framework, when to call "ThreadLocal.remove()" function?

---------------------
